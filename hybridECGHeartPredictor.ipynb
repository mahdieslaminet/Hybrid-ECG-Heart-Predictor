{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the dataset using kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading dataset... Please wait.\")\n",
    "path = kagglehub.dataset_download(\"mohamedeldakrory8/ecg-heart-categorization-dataset-image-version\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_folder_name = \"ECG Heartbeat Categorization Dataset Image Version\"\n",
    "data_dir = os.path.join(path, content_folder_name)\n",
    "\n",
    "# Define train and test paths\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Path Validation and Auto-Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(train_dir):\n",
    "    print(\"Warning: Expected 'train' path not found. Checking directory structure...\")\n",
    "    print(\"Main directory contents:\", os.listdir(path))\n",
    "\n",
    "    # Attempt to find the correct sub-folder automatically\n",
    "    sub_folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    if sub_folders:\n",
    "        data_dir = os.path.join(path, sub_folders[0])\n",
    "        train_dir = os.path.join(data_dir, 'train')\n",
    "        test_dir = os.path.join(data_dir, 'test')\n",
    "        print(f\"Corrected Data Directory: {data_dir}\")\n",
    "    else:\n",
    "        print(\"Error: No sub-folders found in the downloaded path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ImageDataGenerator Setup\n",
    "According to the article, images are resized to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading Training Set...\")\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Load Validation/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Test Set...\")\n",
    "val_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 30)\n",
    "print(f\"Number of classes found: {train_data.num_classes}\")\n",
    "print(f\"Class labels (Disease types): {list(train_data.class_indices.keys())}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Hybrid DLA-ANN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_model(num_classes=7):\n",
    "    base_model = tf.keras.applications.VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(256),\n",
    "        layers.Activation('swish'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.Recall(name='sensitivity'), tf.keras.metrics.Precision(name='precision')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_final_model(num_classes=7)\n",
    "print(\"DLA-ANN Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_data.batch_size = BATCH_SIZE\n",
    "val_data.batch_size = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStarting Optimized Training Process...\")\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=100,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ecg_dla_ann_model.h5')\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model saved successfully as 'ecg_dla_ann_model.h5'\")\n",
    "print(\"Based on Hybrid deep learning framework for heart disease prediction.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"Final Model Evaluation on Test Data\")\n",
    "print(\"=\"*30)\n",
    "results = model.evaluate(val_data, steps=len(val_data))\n",
    "metrics_names = model.metrics_names\n",
    "for name, value in zip(metrics_names, results):\n",
    "    if name != 'loss':\n",
    "        print(f\"Final {name.capitalize()}: {value*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Final Loss: {value:.4f}\")\n",
    "print(\"\\nComparison with Article 3 Targets:\")\n",
    "print(f\"Target Accuracy: 93.6% | Your Accuracy: {results[1]*100:.2f}%\")\n",
    "print(f\"Target Sensitivity: 97.4% | Your Sensitivity: {results[2]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'ecg_dla_ann_model.h5'\n",
    "if os.path.exists(model_path):\n",
    "    inference_model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: Saved model file not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, len(val_data.filepaths))\n",
    "img_path = val_data.filepaths[random_idx]\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_batch = np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Selected ECG Signal Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('ecg_dla_ann_model.h5')\n",
    "preds = loaded_model.predict(img_batch)\n",
    "class_idx = np.argmax(preds)\n",
    "label_code = list(train_data.class_indices.keys())[class_idx]\n",
    "prob = preds[0][class_idx] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "موارد زیر تنها برای نمایش خروجی فارسی به کاربر می باشد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_labels = {\n",
    "    'N': {'title': 'وضعیت سالم (Normal)', 'msg': 'قلب شما به طور طبیعی می‌تپد. مشکلی مشاهده نشد.', 'color': 'green'},\n",
    "    'M': {'title': 'هشدار بحرانی (Myocardial Infarction)', 'msg': 'علائم سکته قلبی تشخیص داده شد. فوراً به پزشک مراجعه کنید!', 'color': 'red'},\n",
    "    'S': {'title': 'ناهنجاری دهلیزی (S)', 'msg': 'ضربان نامنظم در بخش بالایی قلب تشخیص داده شد. با پزشک مشورت کنید.', 'color': 'orange'},\n",
    "    'V': {'title': 'ناهنجاری بطنی (V)', 'msg': 'ضربان نامنظم در بخش پایینی قلب تشخیص داده شد. بررسی پزشکی توصیه می‌شود.', 'color': 'orange'},\n",
    "    'F': {'title': 'ضربان ترکیبی (F)', 'msg': 'اختلال جزئی در ریتم تپش مشاهده شد.', 'color': 'orange'},\n",
    "    'F-resample': {'title': 'اختلال ریتم (F-res)', 'msg': 'ناهنجاری در ریتم ضربان قلب شناسایی شد.', 'color': 'orange'},\n",
    "    'Q': {'title': 'نامشخص (Unknown)', 'msg': 'کیفیت تصویر برای تشخیص پایین است یا سیگنال نامفهوم است.', 'color': 'gray'}\n",
    "}\n",
    "predictions = inference_model.predict(img_batch)\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "info = fa_labels.get(label_code, {'title': 'خطا', 'msg': 'دسته ناشناخته', 'color': 'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(train_data.class_indices.keys())\n",
    "predicted_label = class_labels[predicted_class_index]\n",
    "confidence = predictions[0][predicted_class_index] * 100\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {predicted_label} ({confidence:.2f}%)\", color='green')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- گزارش تحلیل قلب ---\")\n",
    "print(f\"نتیجه تشخیص: {info['title']}\")\n",
    "print(f\"توضیح برای کاربر: {info['msg']}\")\n",
    "print(f\"میزان اطمینان سیستم: {prob:.2f} درصد\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
